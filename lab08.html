<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <title>lecture note</title>
        <!-- Bootstrap CSS CDN -->
        <link rel="stylesheet" href="css/bootstrap.min.css">
        <!-- Our Custom CSS -->
        <link rel="stylesheet" href="css/style.css">
        <!-- Scrollbar Custom CSS -->
        <link rel="stylesheet" href="css/jquery.mCustomScrollbar.min.css">
        <link rel="stylesheet" href="css/font-awesome.min.css">
        <link rel="stylesheet" href="css/vs2015.min.css">
        <script src="js/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
    </head>
    <body>
        <div class="wrapper container">
            <!-- Sidebar Holder -->
            <nav id="sidebar">
                <div class="sidebar-header">
                    <h3 class="korean">김성훈 교수님</h3>
                    <a href="https://www.inflearn.com/course/%EA%B8%B0%EB%B3%B8%EC%A0%81%EC%9D%B8-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%95%EC%A2%8C/" target="_blank" data-toggle="tooltip" title="강의 보러 가기 click me"><h5 class="korean">모두를 위한 머신러닝/딥러닝</h5></a>
                </div>
                <ul class="list-unstyled components">
                    <p class="korean">INDEX</p>
                    <li>
                        <a href="index.html">Intro</a>
                    </li>
                    <li>
                        <a href="#homeSubmenu" data-toggle="collapse" aria-expanded="false">Lect</a>
                        <ul class="korean collapse list-unstyled" id="homeSubmenu">
                            <li><a href="lect01.html">Lect01. 머신러닝의 개념과 용어</a></li>
                            <li><a href="lect02.html">Lect02. Linear Regression의 개념</a></li>
                            <li><a href="lect03.html">Lect03. Linear Regression cost 함수 최소화</a></li>
                            <li><a href="lect04.html">Lect04. 여러개의 입력(feature)의 Linear Regression</a></li>
                            <li><a href="lect05.html">Lect05. Logistic Classification (Regression)</a></li>
                            <li><a href="lect06.html">Lect06. Softmax Regression (Multinomial Logistic Regression)</a></li>
                            <li><a href="lect07.html">Lect07. ML의 실용과 몇 가지 팁</a></li>
                            <li><a href="lect08.html">Lect08. 딥러닝의 기본 개념과 문제, 그리고 해결</a></li>
                            <li><a href="lect09.html">Lect09. Neural Network 1 : XOR 문제와 학습방법, Backpropagation</a></li>
                            <li><a href="lect10.html">Lect10. Neural Network 2 : ReLU and 초기 값 정하기 (2006/2007 breakthrough)</a></li>
                            <li><a href="lect11.html">Lect11. Convolutional Neural Networks (a.k.a CNN)</a></li>
                            <li><a href="lect12.html">Lect12. Recurrent Neural Network (a.k.a RNN)</a></li>
                            <li><a href="lect13.html">Lect13. Deep Deep Network AWD에서 GPU와 돌려보기 (powered by AWS)</a></li>
                            <li><a href="lect14.html">Lect14. AWS에서 저렴하게 Spot Instance를 터미네이션 걱정 없이 사용하기</a></li>
                            <li><a href="lect15.html">Lect15. Google Cloud ML을 이용해 TensorFlow 실행하기</a></li>
                        </ul>
                    </li>
                    <li class="active">
                        <a href="#pageSubmenu" data-toggle="collapse" aria-expanded="false">TF example</a>
                        <ul class="korean collapse list-unstyled" id="pageSubmenu">
                            <li><a href="lab01.html">Lab 01. TensorFlow의 설치 및 기본적인 operations</a></li>
                            <li><a href="lab02.html">Lab 02. Tensorflow로 간단한 linear regression을 구현</a></li>
                            <li><a href="lab03.html">Lab 03. Linear Regression의 cost 최소화의 TensorFlow 구현</a></li>
                            <li><a href="lab04_1.html">Lab 04_1. Multi-variable Linear Regression을 TensorFlow에서 구현하기</a></li>
                            <li><a href="lab04_2.html">Lab 04_2. TensorFlow로 파일에서 데이타 읽어오기</a></li>
                            <li><a href="lab05.html">Lab 05. TensorFlow로 Logistic Classification 구현하기</a></li>
                            <li><a href="lab06_1.html">Lab 06_1. TensorFlow로 SoftmaxClassification 구현하기</a></li>
                            <li><a href="lab06_2.html">Lab 06_2. TensorFlow로 Fancy Softmax Classification 구현하기</a></li>
                            <li><a href="lab07_1.html">Lab 07_1. training/test dataset, learning rate, normalization</a></li>
                            <li><a href="lab07_2.html">Lab 07_2. Meet MNIST Dataset</a></li>
                            <li class="active"><a href="lab08.html">Lab 08. Tensor Manipulation</a></li>
                            <li><a href="lab09_1.html">Lab 09_1. XOR을 위한 TensorFlow Deep Network</a></li>
                            <li><a href="lab09_2.html">Lab 09_2. Tensor Board로 Deep Network 들여다 보기</a></li>
                            <li><a href="lab10.html">Lab 10. 딥러닝으로 MNIST 98%이상 해보기</a></li>
                            <li><a href="lab11_1.html">Lab 11_1. TensorFlow의 CNN 기본</a></li>
                            <li><a href="lab11_2.html">Lab 11_2. TensorFlow로 구현하는 MNIST 99%</a></li>
                            <li><a href="lab11_3.html">Lab 11_3. Class, tf.layers, Ensemble (MNIST 99.5%)</a></li>
                            <li><a href="lab12_1.html">Lab 12_1. RNN - Basic</a></li>
                            <li><a href="lab12_2.html">Lab 12_2. RNN - Hi Hello Training</a></li>
                            <li><a href="lab12_3.html">Lab 12_3. Long Sequence RNN</a></li>
                            <li><a href="lab12_4.html">Lab 12_4. Stacked RNN + Softmax Layer</a></li>
                            <li><a href="lab12_5.html">Lab 12_5. Dynamic RNN</a></li>
                            <li><a href="lab12_6.html">Lab 12_6. RNN with Time Series Data</a></li>
                        </ul>
                    </li>
                    
                </ul>
                <ul class="list-unstyled CTAs">
                    <li><a href="https://github.com/hunkim/DeepLearningZeroToAll/archive/master.zip" class="download">Download source</a></li>
                    <br>
                    <!-- <p class="korean">만든이에게</p>
                    <li>
                        <a href="https://www.facebook.com/yoonbaeJeon" target="_blank"><i class="fa fa-facebook-square fa-3x" aria-hidden="true"></i>&nbsp; 페이스북 연락하기</a>
                    </li>
                    <li>
                        <a href="https://plus.google.com/u/0/103969879362546932609" target="_blank"><i class="fa fa-google-plus-square fa-3x" aria-hidden="true"></i>&nbsp; 구글plus 연락하기</a>
                    </li> -->
                    <p>reference</p>
                    <li>
                        <a href="https://www.facebook.com/groups/TensorFlowKR/?fref=nf" target="_blank"><i class="fa fa-facebook-square fa-3x" aria-hidden="true"></i>&nbsp; TensorFlow KR 페이스북</a>
                    </li>
                    <li>
                        <a href="https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/api_docs/" target="_blank"><i class="fa fa-book fa-3x" aria-hidden="true"></i>&nbsp; TensorFlow API doc(KR)</a>
                    </li>
                </ul>
            </nav>
            <!-- Page Content Holder -->
            <div id="content">
                <nav class="navbar navbar-default">
                    <div class="container-fluid">
                        <div class="navbar-header">
                            <button type="button" id="sidebarCollapse" class="btn btn-info navbar-btn">
                            <i class="glyphicon glyphicon-align-left"></i>
                            <span class="korean sidebar_flag">사이드바 접기/펼치기</span>
                            </button>
                        </div>
                        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                            <ul class="nav navbar-nav navbar-right">
                                <li id="content1_list" class="selected"><a>Tensor Manupulation</a></li>
                            </ul>
                        </div>
                    </div>
                </nav>
                <!-- content1 always all content start from index 1 -->
                <div id="content1" hidden>
                    <p>이번 실습강의는 Tensor를 다루는 법에 대한 전반적인 내용에 대한 강의입니다.<br><small><span class="text-danger">p.s.</span>&nbsp;모든 코드에서 <kbd>eval()</kbd>&nbsp;method를 사용할 때 <kbd>eval(session=sess)</kbd>&nbsp;로 <kbd>session</kbd>&nbsp;인자를 넘겨주거나 <kbd>sess=tf.InteractiveSession()</kbd>&nbsp;으로 대화형 세션 객체를 생성해야 오류가 뜨지 않습니다.</small></p><br>
                    <h2>Simple ID array and slicing</h2><br>
                    <img src="img/lab08_1.png" class="img-responsive">
                    <code>t = np.array([0., 1., 2., 3., 4., 5., 6.])</code><br><br>
                    <p>np.array좀더 살펴보기</p>
                    <pre><code class="python">import numpy as np
t = np.array([0., 1., 2., 3., 4., 5., 6.])
pp.pprint(t)
print(t.ndim) # rank
print(t.shape) # shape
print(t[0], t[1], t[-1])
print(t[2:5], t[4:-1])
print(t[:2], t[3:])</code>
<code class="md"># result
array([0., 1., 2., 3., 4., 5., 6.])
1
(7,)
0.0 1.0 6.0
[2. 3. 4.] [4. 5.]
[0. 1.] [3. 4. 5. 6.] &lt;-- 이 부분까지 이해 됬다면 slicing 개념은 완벽히 이해한것.</code></pre>
                    <a href="lab04_2.html#slicing_ref" class="text-primary">Slicing을 까먹었다면 여기서 확인하기</a><br><br>
                    <h2>2D Array</h2><br>
                    <pre><code class="python">t = np.array([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.], [10., 11., 12.]])
pp.pprint(t)
print(t.ndim) # rank
print(t.shape) # shape</code><code class="md"># result
array([[1., 2., 3.],
       [4., 5., 6.],
       [7., 8., 9.]
       [10., 11., 12.]])
2
(4, 3)</code></pre><br><br>
                    <h2>Shape, Rank, Axis</h2><br>
                    <pre><code class="python">import tensorflow as tf
sess = tf.Session()

t = tf.constant([1, 2, 3, 4])
tf.shape(t).eval(session=sess)</code><code class="md"># result
array([4], dtype=int32) &lt;-- rank = 1 --&gt;</code></pre>
                    <pre><code class="python">t = tf.constant([[1, 2], [3, 4]])
tf.shape(t).eval(session=sess)</code><code class="md"># result
array([2, 2], dtype=int32) &lt;-- rank = 2 --&gt;</code></pre>
                    <pre><code class="python">t = tf.constant([[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]],
                 [[13, 14, 15, 16], [17, 18, 19, 20], [21, 22, 23, 24]]])
tf.shape(t).eval(session=sess)</code><code class="md"># result
array([2, 3, 4], dtype=int32) &lt;-- rank = 3 --&gt;</code></pre><br>
                    <h3>Axis</h3><br>
                    <img src="img/lab08_2.png" class="img-responsive">
                    <p><kbd>axis = -1</kbd>&nbsp;은 특별히 마지막 axis를 가리키기도 한다.<br>위 예제에서의 <kbd>axis = -1</kbd>&nbsp;은 <kbd>axis = 3</kbd>&nbsp;와 같다.</p>
                    <div class="line"></div>
                    <h2>Matmul vs multiply</h2><br>
                    <pre><code class="python">import tensorflow as tf
sess = tf.Session()

matrix1 = tf.constant([[1., 2.], [3., 4.]])
matrix2 = tf.constant([[1.], [2.]])
print("Matrix 1 shape", matrix1.shape)
print("Matrix 2 shape", matrix2.shape)
tf.matmul(matrix1, matrix2).eval(session=sess)</code><code class="md"># result
Matrix 1 shape (2, 2)
Matrix 2 shape (2, 1)
array([[  5.],
       [ 11.]], dtype=float32)</code></pre>
                    <pre><code class="python">(matrix1 * matrix2).eval(session=sess)</code><code class="md"># result
array([[ 1., 2.],
       [ 6., 8.]], dtype=float32)</code></pre>
                    <p class="text-danger">※주의 : 행렬 곱셈과 일반적인 곱셈의 결과는 완전히 다르다</p>

                    <div class="line"></div>

                    <h2>Broadcasting&nbsp;<i class="fa fa-warning"></i></h2>
                    <p>Matrix shape이 다르더라도 연산이 가능하게 되는 것을 broadcasting이라 한다.</p><br>
                    <pre><code class="python">import tensorflow as tf
sess = tf.InteractiveSession()

matrix1 = tf.constant([[1., 2.]])
matrix2 = tf.constant(3.) # [[3., 3.]]으로 broadcasting됨
(matrix1 + matrix2).eval()</code><code class="md"># result
array([[ 4., 5.]], dtype=float32) &lt;-- tensor의 shape이 달라도 shape을 맞춰준다 --&gt;</code></pre>
                    <pre><code class="python">matrix1 = tf.constant([[1., 2.]])
matrix2 = tf.constant([3., 4.]) # [[3., 4.]]으로 broadcasting됨
(matrix1 + matrix2).eval()</code><code class="md"># result
array([[ 4., 6.]], dtype=float32)</code></pre>
                    <pre><code class="python">matrix1 = tf.constant([[1., 2.]])
matrix2 = tf.constant([[3.], [4.]]) # [[3., 3.], [4., 4.]]으로 broadcasting됨
(matrix1 + matrix2).eval()</code><code class="md"># result
array([[ 4., 5.],
       [ 5., 6.]], dtype=float32)</code></pre>
                    
                    <div class="line"></div>

                    <h2>Reduce mean</h2><br>
                    <pre><code class="python">tf.reduce_mean([1, 2], axis=0).eval()</code><code class="md"># result
1
&lt;-- 1.5가 아닌 1인 이유는 tensor의 dtype이 integer이기 때문 --&gt;</code></pre><br>
                    <p>축(axis)을 정하지 않고 reduce_mean</p>
                    <pre><code class="python">x = [[1., 2.],
     [3., 4.]]

tf.reduce_mean(x).eval()</code><code class="md"># result
2.5     &lt;-- 모든 축에 대하여 평균을 구함 --&gt;</code></pre>
                    <p>축(axis)을 정하여 reduce_mean</p>
                    <pre><code class="python">tf.reduce_mean(x, axis=0).eval()
tf.reduce_mean(x, axis=1).eval()
tf.reduce_mean(x, axis=-1).eval()</code><code class="md"># result1
array([2., 3.], dtype=float32)
# result2
array([ 1.5, 3.5], dtype=float32)
# result3
array([ 1.5, 3.5], dtype=float32)</code></pre>

                    <div class="line"></div>

                    <h2>Reduce sum</h2><br>
                    <pre><code class="python">x = [[1., 2.],
     [3., 4.]]

tf.reduce_sum(x).eval()     # 1

tf.reduce_sum(x, axis=0).eval()     # 2

tf.reduce_sum(x, axis=-1).eval()    # 3

tf.reduce_mean(tf.reduce_sum(x, axis=-1)).eval()    # 4</code><code class="md">
# result1
10.0    &lt;-- 축(axis)을 정하지 않은 경우 모든 element에 대한 sum을 구함 --&gt;
# result2
array([ 4., 6.], dtype=float32)
# result3
array([ 3., 7.], dtype=float32)
# result4
5.0     &lt;-- array([3., 7.])의 평균 --&gt;</code></pre>

                    <div class="line"></div>

                    <h2>Argmax</h2>
                    <p>가장 큰 element의 위치(index)를 return해준다.</p><br>
                    <pre><code class="python">x = [[0, 1, 2],
     [2, 1, 0]]

tf.argmax(x, axis=0).eval()</code><code class="md"># result
array([1, 0, 0], dtype=int64)
&lt;-- 0과 2를 비교한 것 중 큰 index인 1반환--&gt;
&lt;-- 1과 1을 비교한 것 중 큰 index인 0반환 (같으면 index가 작은 쪽)--&gt;
&lt;-- 2와 0을 비교한 것 중 큰 index인 0반환--&gt;</code></pre>
                    <pre><code class="python">tf.argmax(x, axis=1).eval()</code><code class="md"># result
array([2, 0], dtype=int64)
&lt;-- tf.argmax(x, axis=-1 ) 일때도 결과는 같다--&gt;</code></pre>

                    <div class="line"></div>

                    <h2>Reshape**</h2><br>
                    <pre><code class="python">t = np.array([
                [
                    [0, 1, 2],
                    [3, 4, 5]
                ],
                [
                    [6, 7, 8],
                    [9, 10, 11]
                ]
            ])

t.shape</code><code class="md"># result
(2, 2, 3)   &lt;-- rank = 3 --&gt;</code></pre>
                    <pre><code class="python">tf.reshape(t, shape=[-1, 3]).eval()  # -1은 개수를 알 수 없기 때문에 ALL을 뜻 함</code><code class="md"># result
array([[ 0, 1, 2],
       [ 3, 4, 5],
       [ 6, 7, 8],
       [ 9, 10, 11]])
&lt;-- rank = 2 --&gt;</code></pre>
                    <pre><code class="python">tf.reshape(t, shape=[-1, 1, 3]).eval()</code><code class="md"># result
array([[[ 0, 1, 2]],
       [[ 3, 4, 5]],
       [[ 6, 7, 8]],
       [[ 9, 10, 11]]])
&lt;-- rank = 3 --&gt;</code></pre><br>

                    <h2>Reshape (squeeze, expand)</h2><br>
                    <p>squeeze&nbsp;<a href="https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/api_docs/python/array_ops.html#squeeze" target="_blank" class="text-primary">더 알아보기</a></p>
                    <pre><code class="python">tf.squeeze([[0], [1], [2]]).eval()</code><code class="md"># result
array([0, 1, 2], dtype=int32)

&lt;-- rank가 2에서 1로 줄어든다 --&gt;</code></pre>
                    <p>expand&nbsp;<a href="https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/api_docs/python/array_ops.html#expand_dims" target="_blank" class="text-primary">더 알아보기</a></p>
                    <pre><code class="python">tf.expand_dims([0, 1, 2], 1).eval()</code><code class="md"># result
array([[0],
       [1],
       [2]], dtype=int32)

&lt;-- rank가 1에서 2로 증가한다 --&gt;</code></pre>

                    <div class="line"></div>

                    <h2>One hot</h2><br>
                    <pre><code class="python">tf.one_hot([[0], [1], [2], [0]], depth=3).eval()</code><code class="md"># result
array([[[ 1., 0., 0.]],
       [[ 0., 1., 0.]],
       [[ 0., 0., 1.]],
       [[ 1., 0., 0.]]], dtype=float32)</code></pre>
                    <p><small>지정된 <kbd>depth</kbd>&nbsp;만큼의 shape으로 one_hot encoding이 일어나고,<br><kbd>int -> float</kbd>&nbsp;의 형 변환과 <kbd>rank + 1</kbd>&nbsp;이란 변화가 생긴다.</small></p><br>
                    <p><small>의도치 않게 증가된 rank를 다시 <kbd>tf.reshape</kbd>&nbsp;로 바꿀 수 있다.</small></p>
                    <pre><code class="python">t = tf.one_hot([[0], [1], [2], [0]], depth=3)
tf.reshape(t, shape=[-1, 3]).eval() # shape의 parameter개수가 rank개수</code><code class="md"># result
array([[ 1., 0., 0.],
       [ 0., 1., 0.],
       [ 0., 0., 1.],
       [ 1., 0., 0.]], dtype=float32)</code></pre>

                    <div class="line"></div>

                    <h2>Casting</h2>
                    <p>형 변환이 필요할 때 사용하는 method.</p><br>
                    <pre><code class="python">tf.cast([1.8, 2.2, 3.3, 4.9], tf.int32).eval()</code><code class="md"># result
array([1, 2, 3, 4], dtype=int32)
</code></pre>
                    <pre><code class="python">tf.cast([True, False, 1 == 1, 0 == 1], tf.int32).eval()</code><code class="md"># result
array([1, 0, 1, 0], dtype=int32)
&lt;-- accuracy 계산 시 True의 개수를 세야 할 때 int로 casting 후 사용 가능 --&gt;</code></pre>

                    <div class="line"></div>

                    <h2>Stack</h2><br>
                    <pre><code class="python">x = [1, 4]
y = [2, 5]
z = [3, 6]

# Pack along first dim.
tf.stack([x, y, z]).eval()</code><code class="md"># result
array([[1, 4],
       [2, 5],
       [3, 6]], dtype=int32)</code></pre>
                    <pre><code class="python">tf.stack([x, y, z], axis=1).eval()
tf.stack([x, y, z], axis=0).eval()
tf.stack([x, y, z], axis=-1).eval()</code><code class="md"># result
array([[1, 2, 3],
       [4, 5, 6]], dtype=int32)

array([[1, 4],
       [2, 5],
       [3, 6]], dtype=int32)

array([[1, 2, 3],
       [4, 5, 6]], dtype=int32)
</code></pre>
                    <div class="line"></div>

                    <h2>Ones and Zeros like</h2>
                    <p>기존의 tensor와 같은 shape의 1 또는 0으로 채워진 tensor 생성</p><br>
                    <pre><code class="python">x = [[0, 1, 2],
     [2, 1, 0]]

tf.ones_like(x).eval()</code><code class="md"># result
array([[1, 1, 1],
       [1, 1, 1]], dtype=int32)</code></pre>
                    <pre><code class="python">x = [[0, 1, 2],
     [2, 1, 0]]

tf.zeros_like(x).eval()</code><code class="md"># result
array([[0, 0, 0],
       [0, 0, 0]], dtype=int32)</code></pre>

                    <div class="line"></div>

                    <h2>Zip</h2>
                    <p>python 내장 함수. 링크를 참조 <a href="https://wikidocs.net/32#zip" target="_blank" class="text-primary">https://wikidocs.net/32#zip</a></p><br>
                    <pre><code class="python">for x, y in zip([1, 2, 3], [4, 5, 6]):
    print(x, y)</code><code class="md"># result
1 4
2 5
3 6</code></pre>
                    <pre><code class="python">for x, y, z in zip([1, 2, 3], [4, 5, 6], [7, 8, 9]):
    print(x, y, z)</code><code class="md"># result
1 4 7
2 5 8
3 6 9</code></pre>
                </div>
               
                <!-- page navigation -->
                <div class="footer">
                    <ul class="pager">
                        <li class="previous" id="prev_button" style="color:#00BFFF;"><a href="#">Previous</a></li>
                        <li class="next" id="next_button" style="color:#00BFFF;"><a href="#">Next</a></li>
                    </ul>
                </div>
            </div>
        </div>
        
        <!-- jQuery CDN -->
        <script src="js/jquery-1.12.0.min.js"></script>
        <!-- Bootstrap Js CDN -->
        <script src="js/bootstrap.min.js"></script>
        <!-- jQuery Custom Scroller CDN -->
        <script src="js/jquery.mCustomScrollbar.concat.min.js"></script>
        
        <script type="text/javascript">
        $(document).ready(function () {
        $("#sidebar").mCustomScrollbar({
        theme: "minimal"
        });
        $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
        });
        var cnt = 0;
        for(i=1;;i++){
        var local_id = "#content"+i;
        if($(local_id).length==0) break;
        cnt++;
        }
        if(cnt<=1){
        $("#prev_button").hide();
        $("#next_button").hide();
        $(".sidebar_flag").show();
        }
        var current = 1;
        var local_id = "#content"+current;
        $(local_id).show();
        local_id+="_list";
        $(local_id).addClass("selected");
        $("#prev_button").click(function(){
        if(current>1){
        local_id = "#content"+current;
        $(local_id).hide();
        local_id += "_list";
        $(local_id).removeClass("selected");
        current--;
        local_id = "#content"+current;
        $(local_id).show();
        local_id += "_list";
        $(local_id).addClass("selected");
        }
        });
        $("#next_button").click(function(){
        if(current<cnt){
        local_id = "#content"+current;
        $(local_id).hide();
        local_id += "_list";
        $(local_id).removeClass("selected");
        current++;
        local_id = "#content"+current;
        $(local_id).show();
        local_id += "_list";
        $(local_id).addClass("selected");
        }
        });
        $('[data-toggle="tooltip"]').tooltip();
        });
        $("#showfullcode").click(function(){
            $("#fullcode").toggle();
            $(this).html($("#showfullcode").text()=='show full code'? 'hide full code' : 'show full code');
        })
        </script>
    </body>
</html>