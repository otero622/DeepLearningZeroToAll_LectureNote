<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <title>lecture note</title>
        <!-- Bootstrap CSS CDN -->
        <link rel="stylesheet" href="css/bootstrap.min.css">
        <!-- Our Custom CSS -->
        <link rel="stylesheet" href="css/style.css">
        <!-- Scrollbar Custom CSS -->
        <link rel="stylesheet" href="css/jquery.mCustomScrollbar.min.css">
        <link rel="stylesheet" href="css/font-awesome.min.css">
        <link rel="stylesheet" href="css/vs2015.min.css">
        <script src="js/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
    </head>
    <body>
        <div class="wrapper">
            <!-- Sidebar Holder -->
            <nav id="sidebar">
                <div class="sidebar-header">
                    <h3 class="korean">김성훈 교수님</h3>
                    <a href="https://www.inflearn.com/course/%EA%B8%B0%EB%B3%B8%EC%A0%81%EC%9D%B8-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%95%EC%A2%8C/" target="_blank" data-toggle="tooltip" title="강의 보러 가기 click me"><h5 class="korean">모두를 위한 머신러닝/딥러닝</h5></a>
                </div>
                <ul class="list-unstyled components">
                    <p class="korean">INDEX</p>
                    <li>
                        <a href="index.html">Intro</a>
                    </li>
                    <li>
                        <a href="#homeSubmenu" data-toggle="collapse" aria-expanded="false">Lect</a>
                        <ul class="korean collapse list-unstyled" id="homeSubmenu">
                            <li><a href="lect01.html">Lect01. 머신러닝의 개념과 용어</a></li>
                            <li><a href="lect02.html">Lect02. Linear Regression의 개념</a></li>
                            <li><a href="lect03.html">Lect03. Linear Regression cost 함수 최소화</a></li>
                            <li><a href="lect04.html">Lect04. 여러개의 입력(feature)의 Linear Regression</a></li>
                            <li><a href="lect05.html">Lect05. Logistic Classification (Regression)</a></li>
                            <li><a href="lect06.html">Lect06. Softmax Regression (Multinomial Logistic Regression)</a></li>
                            <li><a href="lect07.html">Lect07. ML의 실용과 몇 가지 팁</a></li>
                            <li><a href="lect08.html">Lect08. 딥러닝의 기본 개념과 문제, 그리고 해결</a></li>
                            <li><a href="lect09.html">Lect09. Neural Network 1 : XOR 문제와 학습방법, Backpropagation</a></li>
                            <li><a href="lect10.html">Lect10. Neural Network 2 : ReLU and 초기 값 정하기 (2006/2007 breakthrough)</a></li>
                            <li><a href="lect11.html">Lect11. Convolutional Neural Networks (a.k.a CNN)</a></li>
                            <li><a href="lect12.html">Lect12. Recurrent Neural Network (a.k.a RNN)</a></li>
                            <li><a href="lect13.html">Lect13. Deep Deep Network AWD에서 GPU와 돌려보기 (powered by AWS)</a></li>
                            <li><a href="lect14.html">Lect14. AWS에서 저렴하게 Spot Instance를 터미네이션 걱정 없이 사용하기</a></li>
                            <li><a href="lect15.html">Lect15. Google Cloud ML을 이용해 TensorFlow 실행하기</a></li>
                        </ul>
                    </li>
                    <li class="active">
                        <a href="#pageSubmenu" data-toggle="collapse" aria-expanded="false">TF example</a>
                        <ul class="korean collapse list-unstyled" id="pageSubmenu">
                            <li><a href="lab01.html">Lab 01. TensorFlow의 설치 및 기본적인 operations</a></li>
                            <li><a href="lab02.html">Lab 02. Tensorflow로 간단한 linear regression을 구현</a></li>
                            <li><a href="lab03.html">Lab 03. Linear Regression의 cost 최소화의 TensorFlow 구현</a></li>
                            <li class="active"><a href="lab04_1.html">Lab 04_1. Multi-variable Linear Regression을 TensorFlow에서 구현하기</a></li>
                            <li><a href="lab04_2.html">Lab 04_2. TensorFlow로 파일에서 데이타 읽어오기</a></li>
                            <li><a href="lab05.html">Lab 05. TensorFlow로 Logistic Classification 구현하기</a></li>
                            <li><a href="lab06_1.html">Lab 06_1. TensorFlow로 SoftmaxClassification 구현하기</a></li>
                            <li><a href="lab06_2.html">Lab 06_2. TensorFlow로 Fancy Softmax Classification 구현하기</a></li>
                            <li><a href="lab07_1.html">Lab 07_1. training/test dataset, learning rate, normalization</a></li>
                            <li><a href="lab07_2.html">Lab 07_2. Meet MNIST Dataset</a></li>
                            <li><a href="lab08.html">Lab 08. Tensor Manipulation</a></li>
                            <li><a href="lab09_1.html">Lab 09_1. XOR을 위한 TensorFlow Deep Network</a></li>
                            <li><a href="lab09_2.html">Lab 09_2. Tensor Board로 Deep Network 들여다 보기</a></li>
                            <li><a href="lab10.html">Lab 10. 딥러닝으로 MNIST 98%이상 해보기</a></li>
                            <li><a href="lab11_1.html">Lab 11_1. TensorFlow의 CNN 기본</a></li>
                            <li><a href="lab11_2.html">Lab 11_2. TensorFlow로 구현하는 MNIST 99%</a></li>
                            <li><a href="lab11_3.html">Lab 11_3. Class, tf.layers, Ensemble (MNIST 99.5%)</a></li>
                            <li><a href="lab12_1.html">Lab 12_1. RNN - Basic</a></li>
                            <li><a href="lab12_2.html">Lab 12_2. RNN - Hi Hello Training</a></li>
                            <li><a href="lab12_3.html">Lab 12_3. Long Sequence RNN</a></li>
                            <li><a href="lab12_4.html">Lab 12_4. Stacked RNN + Softmax Layer</a></li>
                            <li><a href="lab12_5.html">Lab 12_5. Dynamic RNN</a></li>
                            <li><a href="lab12_6.html">Lab 12_6. RNN with Time Series Data</a></li>
                        </ul>
                    </li>
                    
                </ul>
                <ul class="list-unstyled CTAs">
                    <li><a href="https://github.com/hunkim/DeepLearningZeroToAll/archive/master.zip" class="download">Download source</a></li>
                    <br>
                    <p class="korean">만든이에게</p>
                    <li>
                        <a href="https://www.facebook.com/yoonbaeJeon" target="_blank"><i class="fa fa-facebook-square fa-3x" aria-hidden="true"></i>&nbsp; 페이스북 연락하기</a>
                    </li>
                    <li>
                        <a href="https://plus.google.com/u/0/103969879362546932609" target="_blank"><i class="fa fa-google-plus-square fa-3x" aria-hidden="true"></i>&nbsp; 구글plus 연락하기</a>
                    </li>
                    <p>reference</p>
                    <li>
                        <a href="https://www.facebook.com/groups/TensorFlowKR/?fref=nf" target="_blank"><i class="fa fa-facebook-square fa-3x" aria-hidden="true"></i>&nbsp; TensorFlow KR 페이스북</a>
                    </li>
                    <li>
                        <a href="https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/api_docs/" target="_blank"><i class="fa fa-book fa-3x" aria-hidden="true"></i>&nbsp; TensorFlow API doc(KR)</a>
                    </li>
                </ul>
            </nav>
            <!-- Page Content Holder -->
            <div id="content">
                <nav class="navbar navbar-default">
                    <div class="container-fluid">
                        <div class="navbar-header">
                            <button type="button" id="sidebarCollapse" class="btn btn-info navbar-btn">
                            <i class="glyphicon glyphicon-align-left"></i>
                            <span class="korean">사이드바 접기/펼치기</span>
                            </button>
                        </div>
                        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                            <ul class="nav navbar-nav navbar-right">
                                <li id="content1_list" class="selected"><a>Linear Regression의 cost 최소화 TensorFlow 구현</a></li>
                            </ul>
                        </div>
                    </div>
                </nav>
                <!-- content1 always all content start from index 1 -->
                <div id="content1" hidden>
                    <h2>Hypothesis using matrix</h2><br>
                    <p><img alt="H(x_{1}, x_{2}, x_{3}) = w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3}" src="https://latex.codecogs.com/gif.latex?H%28x_%7B1%7D%2C%20x_%7B2%7D%2C%20x_%7B3%7D%29%20%3D%20w_%7B1%7Dx_%7B1%7D%20&amp;plus;%20w_%7B2%7Dx_%7B2%7D%20&amp;plus;%20w_%7B3%7Dx_%7B3%7D%20&amp;"><br></p>
                    
                    <img src="img/lab03_7.png" class="img-responsive" alt="Responsive image">
                    <p>multi variables로 W찾기</p>
                    <p>학습해야할 Weight(W)의 개수 : 3개( <em>w1, w2, w3</em> )</p><br><br>
                    <h3>multi variable hypothesis</h3>
                    <p><img alt="H(x_{1}, x_{2}, x_{3}) = w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} + b" src="https://latex.codecogs.com/gif.latex?H%28x_%7B1%7D%2C%20x_%7B2%7D%2C%20x_%7B3%7D%29%20%3D%20w_%7B1%7Dx_%7B1%7D%20&amp;plus;%20w_%7B2%7Dx_%7B2%7D%20&amp;plus;%20w_%7B3%7Dx_%7B3%7D%20&amp;plus;%20b"><br></p>
                    <p>multi_variable_linear_regression.py</p>
                                                            <pre><code class="python"># Lab 4 Multi-variable linear regression
import tensorflow as tf
tf.set_random_seed(777)  # for reproducibility

x1_data = [73., 93., 89., 96., 73.]
x2_data = [80., 88., 91., 98., 66.]
x3_data = [75., 93., 90., 100., 70.]

y_data = [152., 185., 180., 196., 142.]

# placeholders for a tensor that will be always fed.
x1 = tf.placeholder(tf.float32)
x2 = tf.placeholder(tf.float32)
x3 = tf.placeholder(tf.float32)

Y = tf.placeholder(tf.float32)

w1 = tf.Variable(tf.random_normal([1]), name='weight1')
w2 = tf.Variable(tf.random_normal([1]), name='weight2')
w3 = tf.Variable(tf.random_normal([1]), name='weight3')
b = tf.Variable(tf.random_normal([1]), name='bias')

hypothesis = x1 * w1 + x2 * w2 + x3 * w3 + b
# cost/loss function
cost = tf.reduce_mean(tf.square(hypothesis - Y))

# Minimize. Need a very small learning rate for this data set
optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)
train = optimizer.minimize(cost)

# Launch the graph in a session.
sess = tf.Session()
# Initializes global variables in the graph.
sess.run(tf.global_variables_initializer())

for step in range(2001):
    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],
    feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data})
    if step % 10 == 0:
        print(step, "Cost: ", cost_val, "\nPrediction:\n", hy_val)</code></pre>
                    <br><p>결과 창</p>
                    <pre><code class="md"># result
0 Cost:  62547.3 
Prediction:
 [-75.963455 -78.27629  -83.83015  -90.80437  -56.976486]
10 Cost:  14.468595 
Prediction:
 [145.26408 187.59541 178.152   194.48584 145.81136]
20 Cost:  13.822476 
Prediction:
 [145.9478  188.39001 178.94908 195.3521  146.41212]
30 Cost:  13.749173 
Prediction:
 [145.96422 188.38261 178.95592 195.35777 146.4012 ]
40 Cost:  13.676283 
Prediction:
 [145.97855 188.37279 178.96031 195.36081 146.38843]
50 Cost:  13.603777 
Prediction:
 [145.99286 188.36302 178.96472 195.36388 146.3757 ]
60 Cost:  13.5316725 
Prediction:
 [146.00713 188.35326 178.96912 195.3669  146.36302]
70 Cost:  13.459955 
Prediction:
 [146.02135 188.34352 178.97348 195.36992 146.35036]

...

1940 Cost:  5.0503902 
Prediction:
 [148.1074  186.91605 179.61594 195.80896 144.49889]
1950 Cost:  5.024487 
Prediction:
 [148.11597 186.91019 179.61856 195.81073 144.4913 ]
1960 Cost:  4.9987173 
Prediction:
 [148.12451 186.90434 179.6212  195.8125  144.48375]
1970 Cost:  4.973094 
Prediction:
 [148.13303 186.89851 179.62383 195.81427 144.47621]
1980 Cost:  4.9475794 
Prediction:
 [148.14154 186.8927  179.62646 195.81604 144.4687 ]
1990 Cost:  4.9222364 
Prediction:
 [148.15001 186.8869  179.62907 195.81778 144.46121]
2000 Cost:  4.897023 
Prediction:
 [148.15846 186.88113 179.63168 195.81953 144.45374]</code></pre>
                    <div class="line"></div>
                    <h2>Matrix</h2>
                    <p><img alt="(x_{1} \; x_{2}\; x_{3}) \begin{pmatrix} w_{1} \\w_{2}\\w_{3} \end{pmatrix}=(x_{1}w_{1}+x_{2}w_{2}+x_{3}w_{3})" src="https://latex.codecogs.com/gif.latex?%28x_%7B1%7D%20%5C%3B%20x_%7B2%7D%5C%3B%20x_%7B3%7D%29%20%5Cbegin%7Bpmatrix%7D%20w_%7B1%7D%20%5C%5Cw_%7B2%7D%5C%5Cw_%7B3%7D%20%5Cend%7Bpmatrix%7D%3D%28x_%7B1%7Dw_%7B1%7D&amp;plus;x_%7B2%7Dw_%7B2%7D&amp;plus;x_%7B3%7Dw_%7B3%7D%29"><br></p><br>
                    <p><img alt="\LARGE H(x)=XW" src="https://latex.codecogs.com/gif.latex?%5CLARGE%20H%28x%29%3DXW"><br></p><br>
                    <p>multi_variable_matmul_linear_regression.py</p>
                    <pre><code class="python"># Lab 4 Multi-variable linear regression
import tensorflow as tf
tf.set_random_seed(777)  # for reproducibility

x_data = [[73., 80., 75.],
          [93., 88., 93.],
          [89., 91., 90.],
          [96., 98., 100.],
          [73., 66., 70.]]
y_data = [[152.],
          [185.],
          [180.],
          [196.],
          [142.]]


# placeholders for a tensor that will be always fed.
X = tf.placeholder(tf.float32, shape=[None, 3])
Y = tf.placeholder(tf.float32, shape=[None, 1])
# shape의 첫 인자 None은 원하는 만큼 데이터를 줄 수 있음을 의미
# ex) shape=[3,1]은 2차 matrix [[a], [b], [c]]를 뜻 함

W = tf.Variable(tf.random_normal([3, 1]), name='weight')
b = tf.Variable(tf.random_normal([1]), name='bias')

# Hypothesis
hypothesis = tf.matmul(X, W) + b

# Simplified cost/loss function
cost = tf.reduce_mean(tf.square(hypothesis - Y))

# Minimize
optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)
train = optimizer.minimize(cost)

# Launch the graph in a session.
sess = tf.Session()
# Initializes global variables in the graph.
sess.run(tf.global_variables_initializer())

for step in range(2001):
    cost_val, hy_val, _ = sess.run(
        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})
    if step % 10 == 0:
        print(step, "Cost: ", cost_val, "\nPrediction:\n", hy_val)</code></pre>
                    <br><p>결과 창</p>
                    <pre><code class="md"># result
0 Cost:  22655.951 
Prediction:
 [[22.048063]
 [21.619772]
 [24.096693]
 [22.29302 ]
 [18.633902]]
10 Cost:  6.041774 
Prediction:
 [[155.17453]
 [181.64262]
 [181.76219]
 [193.98836]
 [140.69339]]
20 Cost:  5.813161 
Prediction:
 [[155.5695 ]
 [182.13208]
 [182.23674]
 [194.50673]
 [141.06908]]
30 Cost:  5.7920403 
Prediction:
 [[155.56291]
 [182.13885]
 [182.23573]
 [194.50717]
 [141.0766 ]]

...

1960 Cost:  3.2102711 
Prediction:
 [[154.37814]
 [182.93849]
 [181.85661]
 [194.35728]
 [142.02115]]
1970 Cost:  3.2023563 
Prediction:
 [[154.3734 ]
 [182.94167]
 [181.85507]
 [194.3568 ]
 [142.0248 ]]
1980 Cost:  3.1945186 
Prediction:
 [[154.3687 ]
 [182.94484]
 [181.85358]
 [194.35634]
 [142.02843]]
1990 Cost:  3.1866727 
Prediction:
 [[154.36398]
 [182.948  ]
 [181.85202]
 [194.35585]
 [142.03204]]
2000 Cost:  3.178887 
Prediction:
 [[154.3593 ]
 [182.95117]
 [181.85052]
 [194.3554 ]
 [142.03566]]</code></pre>
                </div>
                <!-- <div id="content2" hidden>helloworld!</div> -->
                <!-- page navigation -->
                <div class="footer">
                    <ul class="pager">
                        <li class="previous" id="prev_button" style="color:#00BFFF;"><a href="#">Previous</a></li>
                        <li class="next" id="next_button" style="color:#00BFFF;"><a href="#">Next</a></li>
                    </ul>
                </div>
            </div>
        </div>
        
        <!-- jQuery CDN -->
        <script src="js/jquery-1.12.0.min.js"></script>
        <!-- Bootstrap Js CDN -->
        <script src="js/bootstrap.min.js"></script>
        <!-- jQuery Custom Scroller CDN -->
        <script src="js/jquery.mCustomScrollbar.concat.min.js"></script>
        
        <script type="text/javascript">
        $(document).ready(function () {
            $("#sidebar").mCustomScrollbar({
                theme: "minimal"
            });
            $('#sidebarCollapse').on('click', function () {
                $('#sidebar, #content').toggleClass('active');
                $('.collapse.in').toggleClass('in');
                $('a[aria-expanded=true]').attr('aria-expanded', 'false');
            });
            var cnt = 0;
            for(i=1;;i++){
                var local_id = "#content"+i;
                if($(local_id).length==0) break;
                cnt++;
            }
            if(cnt<=1){
                $("#prev_button").hide();
                $("#next_button").hide();
            }
            var current = 1;
            var local_id = "#content"+current;
            $(local_id).show();
            local_id+="_list";
            $(local_id).addClass("selected");
            $("#prev_button").click(function(){
                if(current>1){
                    local_id = "#content"+current;
                    $(local_id).hide();
                    local_id += "_list";
                    $(local_id).removeClass("selected");
                    current--;
                    local_id = "#content"+current;
                    $(local_id).show();
                    local_id += "_list";
                    $(local_id).addClass("selected");
                }
            });
            $("#next_button").click(function(){
                if(current<cnt){
                    local_id = "#content"+current;
                    $(local_id).hide();
                    local_id += "_list";
                    $(local_id).removeClass("selected");
                    current++;
                    local_id = "#content"+current;
                    $(local_id).show();
                    local_id += "_list";
                    $(local_id).addClass("selected");
                }
            });
            $('[data-toggle="tooltip"]').tooltip();
        });
        </script>
    </body>
</html>