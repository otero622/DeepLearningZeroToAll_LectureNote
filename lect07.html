<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <title>lecture note</title>
        <!-- Bootstrap CSS CDN -->
        <link rel="stylesheet" href="css/bootstrap.min.css">
        <!-- Our Custom CSS -->
        <link rel="stylesheet" href="css/style.css">
        <!-- Scrollbar Custom CSS -->
        <link rel="stylesheet" href="css/jquery.mCustomScrollbar.min.css">
        <link rel="stylesheet" href="css/font-awesome.min.css">
        <link rel="stylesheet" href="css/vs2015.min.css">
        <script src="js/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
    </head>
    <body>
        <div class="wrapper">
            <!-- Sidebar Holder -->
            <nav id="sidebar">
                <div class="sidebar-header">
                    <h3 class="korean">김성훈 교수님</h3>
                    <a href="https://www.inflearn.com/course/%EA%B8%B0%EB%B3%B8%EC%A0%81%EC%9D%B8-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%95%EC%A2%8C/" target="_blank" data-toggle="tooltip" title="강의 보러 가기 click me"><h5 class="korean">모두를 위한 머신러닝/딥러닝</h5></a>
                </div>
                <ul class="list-unstyled components">
                    <p class="korean">INDEX</p>
                    <li>
                        <a href="index.html">Intro</a>
                    </li>
                    <li class="active">
                        <a href="#homeSubmenu" data-toggle="collapse" aria-expanded="false">Lect</a>
                        <ul class="korean collapse list-unstyled" id="homeSubmenu">
                            <li><a href="lect01.html">Lect01. 머신러닝의 개념과 용어</a></li>
                            <li><a href="lect02.html">Lect02. Linear Regression의 개념</a></li>
                            <li><a href="lect03.html">Lect03. Linear Regression cost 함수 최소화</a></li>
                            <li><a href="lect04.html">Lect04. 여러개의 입력(feature)의 Linear Regression</a></li>
                            <li><a href="lect05.html">Lect05. Logistic Classification (Regression)</a></li>
                            <li><a href="lect06.html">Lect06. Softmax Regression (Multinomial Logistic Regression)</a></li>
                            <li class="active"><a href="lect07.html">Lect07. ML의 실용과 몇 가지 팁</a></li>
                            <li><a href="lect08.html">Lect08. 딥러닝의 기본 개념과 문제, 그리고 해결</a></li>
                            <li><a href="lect09.html">Lect09. Neural Network 1 : XOR 문제와 학습방법, Backpropagation</a></li>
                            <li><a href="lect10.html">Lect10. Neural Network 2 : ReLU and 초기 값 정하기 (2006/2007 breakthrough)</a></li>
                            <li><a href="lect11.html">Lect11. Convolutional Neural Networks (a.k.a CNN)</a></li>
                            <li><a href="lect12.html">Lect12. Recurrent Neural Network (a.k.a RNN)</a></li>
                            <li><a href="lect13.html">Lect13. Deep Deep Network AWD에서 GPU와 돌려보기 (powered by AWS)</a></li>
                            <li><a href="lect14.html">Lect14. AWS에서 저렴하게 Spot Instance를 터미네이션 걱정 없이 사용하기</a></li>
                            <li><a href="lect15.html">Lect15. Google Cloud ML을 이용해 TensorFlow 실행하기</a></li>
                        </ul>
                    </li>
                    <li>
                        <a href="#pageSubmenu" data-toggle="collapse" aria-expanded="false">TF example</a>
                        <ul class="korean collapse list-unstyled" id="pageSubmenu">
                            <li><a href="lab01.html">Lab 01. TensorFlow의 설치 및 기본적인 operations</a></li>
                            <li><a href="lab02.html">Lab 02. Tensorflow로 간단한 linear regression을 구현</a></li>
                            <li><a href="lab03.html">Lab 03. Linear Regression의 cost 최소화의 TensorFlow 구현</a></li>
                            <li><a href="lab04_1.html">Lab 04_1. Multi-variable Linear Regression을 TensorFlow에서 구현하기</a></li>
                            <li><a href="lab04_2.html">Lab 04_2. TensorFlow로 파일에서 데이타 읽어오기</a></li>
                            <li><a href="lab05.html">Lab 05. TensorFlow로 Logistic Classification 구현하기</a></li>
                            <li><a href="lab06_1.html">Lab 06_1. TensorFlow로 SoftmaxClassification 구현하기</a></li>
                            <li><a href="lab06_2.html">Lab 06_2. TensorFlow로 Fancy Softmax Classification 구현하기</a></li>
                            <li><a href="lab07_1.html">Lab 07_1. training/test dataset, learning rate, normalization</a></li>
                            <li><a href="lab07_2.html">Lab 07_2. Meet MNIST Dataset</a></li>
                            <li><a href="lab08.html">Lab 08. Tensor Manipulation</a></li>
                            <li><a href="lab09_1.html">Lab 09_1. XOR을 위한 TensorFlow Deep Network</a></li>
                            <li><a href="lab09_2.html">Lab 09_2. Tensor Board로 Deep Network 들여다 보기</a></li>
                            <li><a href="lab10.html">Lab 10. 딥러닝으로 MNIST 98%이상 해보기</a></li>
                            <li><a href="lab11_1.html">Lab 11_1. TensorFlow의 CNN 기본</a></li>
                            <li><a href="lab11_2.html">Lab 11_2. TensorFlow로 구현하는 MNIST 99%</a></li>
                            <li><a href="lab11_3.html">Lab 11_3. Class, tf.layers, Ensemble (MNIST 99.5%)</a></li>
                            <li><a href="lab12_1.html">Lab 12_1. RNN - Basic</a></li>
                            <li><a href="lab12_2.html">Lab 12_2. RNN - Hi Hello Training</a></li>
                            <li><a href="lab12_3.html">Lab 12_3. Long Sequence RNN</a></li>
                            <li><a href="lab12_4.html">Lab 12_4. Stacked RNN + Softmax Layer</a></li>
                            <li><a href="lab12_5.html">Lab 12_5. Dynamic RNN</a></li>
                            <li><a href="lab12_6.html">Lab 12_6. RNN with Time Series Data</a></li>
                        </ul>
                    </li>
                    
                </ul>
                <ul class="list-unstyled CTAs">
                    <li><a href="https://github.com/hunkim/DeepLearningZeroToAll/archive/master.zip" class="download">Download source</a></li>
                    <br>
                    <!-- <p class="korean">만든이에게</p>
                    <li>
                        <a href="https://www.facebook.com/yoonbaeJeon" target="_blank"><i class="fa fa-facebook-square fa-3x" aria-hidden="true"></i>&nbsp; 페이스북 연락하기</a>
                    </li>
                    <li>
                        <a href="https://plus.google.com/u/0/103969879362546932609" target="_blank"><i class="fa fa-google-plus-square fa-3x" aria-hidden="true"></i>&nbsp; 구글plus 연락하기</a>
                    </li> -->
                    <p>reference</p>
                    <li>
                        <a href="https://www.facebook.com/groups/TensorFlowKR/?fref=nf" target="_blank"><i class="fa fa-facebook-square fa-3x" aria-hidden="true"></i>&nbsp; TensorFlow KR 페이스북</a>
                    </li>
                    <li>
                        <a href="https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/api_docs/" target="_blank"><i class="fa fa-book fa-3x" aria-hidden="true"></i>&nbsp; TensorFlow API doc(KR)</a>
                    </li>
                </ul>
            </nav>

            <!-- Page Content Holder -->
            <div id="content">
                <nav class="navbar navbar-default">
                    <div class="container-fluid">
                        <div class="navbar-header">
                            <button type="button" id="sidebarCollapse" class="btn btn-info navbar-btn">
                            <i class="glyphicon glyphicon-align-left"></i>
                            <span class="korean">사이드바 접기/펼치기</span>
                            </button>
                        </div>
                        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                            <ul class="nav navbar-nav navbar-right">
                                <li id="content1_list" class="selected"><a>Learning rate, Overfitting, and Regularization</a></li>
                                <li id="content2_list"><a>Training / Testing data set</a></li>
                            </ul>
                        </div>
                    </div>
                </nav>
                <!-- content1 always all content start from index 1 -->
                <div id="content1" hidden>
                    <h2>learning_rate</h2><br>
                    <pre><code class="python"># Minimize error using cross entropy
learning_rate = 0.001
cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), reduction_indices=1)) # Cross entropy
optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost) # Gradient Descent</code></pre>
                    <p>일전에 학습할 때는 learning_rate를 임의의 값으로 주고 학습을 하였습니다.<br>만약에 learning_rate를 굉장히 큰 값이나 작은 값으로 준다고 생각해봅시다.</p><br>
                    <h3>Large learning rate<small> : overshooting</small></h3><br>
                    <img src="img/lect07_1.png" class="img-responsive"><br>
                    <p>learning rate가 큰 경우 step마다 이동 폭이 넓어서 어느 순간 곡선 밖으로 팅겨나갈 수 있다. cost함수 값에서 숫자가 아닌 값이 나온다면 overshooting이 일어났다고 볼 수 있다.</p><br>
                    <h3>Small learning rate<small> : takes too long, stops at local minimum</small></h3><br>
                    <img src="img/lect07_2.png" class="img-responsive"><br>
                    <p>이러한 local minimum으로 train이 끝나는 현상을 방지 하기  위해서는 cost함수를 출력해보고 <u>값의 변화가 적을 때</u>는 <b>learning_rate</b>를 <u>올리면 된다.</u></p><br>

                    <h3>Try several learning rates</h3><br>
                    <ul>
                        <li>
                            <big>Observe the cost function</big>
                        </li>
                        <p>&nbsp;&nbsp;초기에 0.01로 시작하여 cost함수의 값을 관찰하면 좋다.</p>
                        <li>
                            <big>Check it goes down in a reasonable rate</big>
                        </li>
                    </ul>
                    <div class="line"></div>
                    <h2>Data(X) preprocessing <span class="text-primary">for gradient descent</span></h2><br>
                    <p>2-Dimensional weight의 경우를 생각해보면 아래와 같이 cost 함수 값을 나타낼 수 있다.</p>
                    <img src="img/lect07_3.png" class="img-responsive">
                    <p>출처 : <a href="https://bishnu.synology.me/wordpress/2014/12/16/cost-function-ii/" target="_blank">https://bishnu.synology.me/wordpress/2014/12/16/cost-function-ii/</a></p><br>
                    <p>input과 output이 다음과 같은 경우의 모델을 예로 들어보자.</p>
                    <img src="img/lect07_4.png" class="img-responsive"><br>
                    <p>x1이 w<sub>1</sub>, x2가 w<sub>2</sub>와 곱해져서 합해진 값이 hypothesis가 되기 때문에, x1에 곱해지는 w<sub>1</sub>값의 spectrum이 w<sub>2</sub>에 비해 상당히 넓게 나타나게 된다.</p>
                    <img src="img/lect07_5.png" class="img-responsive">
                    <p>alpha값(learning_rate)이 잘 잡혀도 w<sub>1</sub>의 길이가 w<sub>2</sub>에 비해 상대적으로 너무 길어서 overshooting의 가능성이 충분히 있다.</p><br>
                    <h3>zero-centered data / normalized data</h3><br>
                    <img src="img/lect07_9.png" class="img-responsive">
                    <p>&nbsp;learning rate를 적당히 잘 잡았음에도 불구하고 overshooting이 일어나거나 cost값이 잘 떨어지지 않는 경우 preprocessor를 잘 적용하였는지 점검 해야한다.<br>
                    보통 input data간의 격차가 큰 경우 해당하므로 preprocessor를 이용하여 data normalization을 해야한다.</p>
                    <div class="line"></div>
                    <h2>Standardization<small><em> - normalization의 한 예</em></small></h2><br>
                    <p><img alt="x^{'}_{j}=\frac{x_{j}-\mu _{j}}{\sigma _{j}}" src="https://latex.codecogs.com/gif.latex?x%5E%7B%27%7D_%7Bj%7D%3D%5Cfrac%7Bx_%7Bj%7D-%5Cmu%20_%7Bj%7D%7D%7B%5Csigma%20_%7Bj%7D%7D">&nbsp;&nbsp;&nbsp;where&nbsp;&nbsp;&mu; = 평균, &sigma; = 분산</p><br>
                    <p>python에서는 단 한줄의 코드로 마무리된다.</p>
                    <kbd>X_std[:,0] = (X[:,0] - X[:,0].mean()) / X[:,0].std()</kbd><br>
                    <p>이 외에도 다양한 normalization이 있는데 여러가지를 찾아보고 적용해보는 것도 좋을거 같다.</p>
                    <div class="line"></div>
                    <h2>Overfitting</h2><br>
                    <ul>
                        <li>
                            <big>Our model is very good with training data set(with memorization)</big>
                        </li><br>
                        <li>
                            <big>Not good at test dataset or in real use</big>
                        </li>
                    </ul><br>
                    <img src="img/lect07_10.png" class="img-responsive">
                    <p>model 1의 경우가 일반적인 model이고 잘 판별할 수 있다.<br>model 2의 경우는 <u>overfitting</u>이 일어난 경우라 볼 수 있다.</p>
                    <h3>Solutions for overfitting</h3><br>
                    <ul>
                        <li>
                            <big>More training data !</big>
                        </li><br>
                        <li>
                            <big>Reduce the number of features</big>
                        </li><br>
                        <li>
                            <big><u>Regularization</u></big>
                        </li><br>
                    </ul><br>
                    <div class="line"></div>
                    <h2>Regularization</h2><br>
                    <ul>
                        <li>
                            <big>Let's not have too big numbers in the weight</big>
                            <p>구부러진 경계 선을 펴!</p>
                        </li>
                    </ul><br>

                    <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img alt="\L =\frac{1}{N}\sum D(S(Wx_{i}+b), L_{i})+\lambda \sum W^{2}" src="https://latex.codecogs.com/gif.latex?%5CL%20%3D%5Cfrac%7B1%7D%7BN%7D%5Csum%20D%28S%28Wx_%7Bi%7D&amp;plus;b%29%2C%20L_%7Bi%7D%29&amp;plus;%5Clambda%20%5Csum%20W%5E%7B2%7D">&nbsp;&nbsp;where &lambda; = regularization strength</p>
                    <p>&lambda;값이 커질 수록 regularization의 중요도를 높게 평가한다는 것이다.</p><br>
                    <p>in tensorflow</p>
                    <kbd>l2reg = 0.001 * tf.reduce_sum(tf.sum(tf.square(W))</kbd>

                </div>
                <div id="content2" hidden="true"> 
                    <h2>Training, validation and test sets</h2><br>
                    <img src="img/lect07_11.png" class="img-responsive">
                    <div class="line"></div>
                    <h2>Online learning</h2><br>
                    <p>기존의 데이터에 대한 학습을 기억한채 새로운 학습을 할 수 있는 모델</p><br>
                    <h4>MNIST Data set</h4><br>
                    <img src="img/lect07_12.png" class="img-responsive">
                    <span><a href="http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz" target="_blank" style="color: red;" data-toggle="tooltip" title="file download">train-images-idx3-ubyte.gz</a> : training set images (9912422 bytes)</span><br>
                    <span><a href="http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz" target="_blank" style="color: red;" data-toggle="tooltip" title="file download">train-labels-idx1-ubyte.gz</a> : training set labels (28881 bytes)</span><br>
                    <span><a href="http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz" target="_blank" style="color: red;" data-toggle="tooltip" title="file download">t10k-images-idx3-ubyte.gz</a> : test set images (1648877 bytes)</span><br>
                    <span><a href="http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz" target="_blank" style="color: red;" data-toggle="tooltip" title="file download">t10k-labels-idx1-ubyte.gz</a> : test set labels (4542 bytes)</span><br><br>
                    <span>출처 : <a href="http://yann.lecun.com/exdb/mnist/" style="color: skyblue;">http://yann.lecun.com/exdb/mnist/</a></span><br><br>
                    <p>위의 Training set Testing set 구조처럼 MNIST도 나눠져있는 것을 확인할 수 있다.</p>
                </div>

                <div class="footer">
                    <ul class="pager">
                        <li class="previous" id="prev_button" style="color:#00BFFF;"><a href="#">Previous</a></li>
                        <li class="next" id="next_button" style="color:#00BFFF;"><a href="#">Next</a></li>
                    </ul>
                </div>
            </div>
        </div>
        
        <!-- jQuery CDN -->
        <script src="js/jquery-1.12.0.min.js"></script>
        <!-- Bootstrap Js CDN -->
        <script src="js/bootstrap.min.js"></script>
        <!-- jQuery Custom Scroller CDN -->
        <script src="js/jquery.mCustomScrollbar.concat.min.js"></script>
        
        <script type="text/javascript">
        $(document).ready(function () {
        $("#sidebar").mCustomScrollbar({
        theme: "minimal"
        });
        $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
        });
        var cnt = 0;
        for(i=1;;i++){
        var local_id = "#content"+i;
        if($(local_id).length==0) break;
        cnt++;
        }
        if(cnt<=1){
        $("#prev_button").hide();
        $("#next_button").hide();
        }
        var current = 1;
        var local_id = "#content"+current;
        $(local_id).show();
        local_id+="_list";
        $(local_id).addClass("selected");
        $("#prev_button").click(function(){
        if(current>1){
        local_id = "#content"+current;
        $(local_id).hide();
        local_id += "_list";
        $(local_id).removeClass("selected");
        current--;
        local_id = "#content"+current;
        $(local_id).show();
        local_id += "_list";
        $(local_id).addClass("selected");
        }
        });
        $("#next_button").click(function(){
        if(current<cnt){
        local_id = "#content"+current;
        $(local_id).hide();
        local_id += "_list";
        $(local_id).removeClass("selected");
        current++;
        local_id = "#content"+current;
        $(local_id).show();
        local_id += "_list";
        $(local_id).addClass("selected");
        }
        });
        $(".recap_question").hover(function(){
            $(this).css("color","red");
            $(this).find(".recap_answer").show();
            }, function(){
            $(this).css("color","black");
            $(this).find(".recap_answer").hide();
        }); 
        $('[data-toggle="tooltip"]').tooltip();
        });
        </script>
    </body>
</html>